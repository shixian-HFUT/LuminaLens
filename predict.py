import torch
from torchvision import transforms
from PIL import Image
import numpy as np
import argparse
import os
from config import get_config
from models import build_model
import warnings

# ç¦ç”¨è­¦å‘Š
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

# è®¾å¤‡é…ç½®
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


class FakeArgs:
    """æ¨¡æ‹Ÿè®­ç»ƒè„šæœ¬çš„å‚æ•°ç»“æ„"""

    def __init__(self, config_path):
        self.cfg = config_path
        self.opts = None
        self.data_path = ""  # ä¿®å¤å…³é”®ç¼ºå¤±å‚æ•°
        self.tag = "predict"
        self.eval = True
        self.pretrained = ''
        self.amp = False
        self.output = 'output'
        self.resume = ''
        self.batch_size = 1  # æ·»åŠ å¯èƒ½éœ€è¦çš„å‚æ•°
        self.num_workers = 0


def load_model(config_path, ckpt_path):
    """å®‰å…¨åŠ è½½æ¨¡å‹"""
    try:
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"Config file {config_path} not found")
        if not os.path.exists(ckpt_path):
            raise FileNotFoundError(f"Model checkpoint {ckpt_path} not found")

        # åˆ›å»ºæ¨¡æ‹Ÿå‚æ•°
        args = FakeArgs(config_path)

        # è·å–é…ç½®
        config = get_config(args)

        # æ„å»ºæ¨¡å‹
        print(f"Building {config.MODEL.TYPE} model...")
        model = build_model(config)

        # åŠ è½½æƒé‡
        checkpoint = torch.load(ckpt_path, map_location=device)
        if "state_dict" in checkpoint:  # å…¼å®¹ä¸åŒä¿å­˜æ ¼å¼
            model.load_state_dict(checkpoint["state_dict"])
        else:
            model.load_state_dict(checkpoint)

        model = model.to(device)
        model.eval()
        return model
    except Exception as e:
        raise RuntimeError(f"Model loading failed: {str(e)}")


def preprocess_image(img_path):
    """ä¸è®­ç»ƒä¸€è‡´çš„é¢„å¤„ç†"""
    try:
        transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ])

        img = Image.open(open(img_path, 'rb')).convert('RGB')
        return transform(img).unsqueeze(0)  # æ·»åŠ batchç»´åº¦
    except Exception as e:
        raise ValueError(f"Image processing error: {str(e)}")


def calculate_score(pred_dist):
    """ä¸è®­ç»ƒä¸€è‡´çš„åˆ†æ•°è®¡ç®—"""
    weights = torch.linspace(1, 10, 10).to(device)
    return torch.sum(pred_dist * weights, dim=1).item()


def predict(image_path):
    """ç«¯åˆ°ç«¯é¢„æµ‹æµç¨‹"""
    try:
        # é…ç½®è·¯å¾„ï¼ˆéœ€ç”¨æˆ·ä¿®æ”¹ï¼ï¼‰
        CONFIG_FILE = "configs/dat_base.yaml"  # æ¨¡å‹é…ç½®æ–‡ä»¶
        MODEL_CKPT = 'model_weights.pth'  # æ¨¡å‹æƒé‡æ–‡ä»¶

        # åŠ è½½æ¨¡å‹
        model = load_model(CONFIG_FILE, MODEL_CKPT)

        # å¤„ç†å›¾åƒ
        input_tensor = preprocess_image(image_path)

        # æ¨ç†é¢„æµ‹
        with torch.no_grad():
            pred_dist, _, _ = model(input_tensor.to(device))

        # è®¡ç®—åˆ†æ•°
        score = calculate_score(pred_dist)
        return round(score, 4)
    except Exception as e:
        raise RuntimeError(f"Prediction failed: {str(e)}")


if __name__ == "__main__":
    # å‘½ä»¤è¡Œç•Œé¢
    parser = argparse.ArgumentParser(
        description="å›¾åƒè´¨é‡è¯„ä¼° (0-10åˆ†)",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument("image_path",
                        type=str,
                        help="è¾“å…¥å›¾åƒè·¯å¾„")
    args = parser.parse_args()

    try:
        # æ‰§è¡Œé¢„æµ‹
        score = predict(args.image_path)

        # æ‰“å°ç¾è§‚ç»“æœ
        print("\n" + "=" * 40)
        print(f"  Predicted Quality Score: {score}/10")
        print("=" * 40)
        print("è´¨é‡ç­‰çº§è¯´æ˜:")
        print("  ğŸŸ¢ 9-10: æä½³è´¨é‡")
        print("  ğŸŸ¡ 7-8:  è‰¯å¥½è´¨é‡")
        print("  ğŸŸ  5-6:  ä¸€èˆ¬è´¨é‡")
        print("  ğŸ”´ 3-4:  è¾ƒå·®è´¨é‡")
        print("  âš« 1-2:  æ— æ³•æ¥å—")
        print("=" * 40)

    except Exception as e:
        print("\nâŒ é”™è¯¯å‘ç”Ÿ:")
        print(f"  {str(e)}")
        print("\næ•…éšœæ’æŸ¥å»ºè®®:")
        print("1. æ£€æŸ¥å›¾åƒè·¯å¾„æ˜¯å¦æ­£ç¡®ï¼ˆæ”¯æŒjpg/pngæ ¼å¼ï¼‰")
        print("2. ç¡®è®¤æ¨¡å‹æ–‡ä»¶å­˜åœ¨ä¸”è·¯å¾„æ­£ç¡®")
        print("3. æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦ä¸è®­ç»ƒæ—¶ä¸€è‡´")
        print("4. å°è¯•é‡æ–°å®‰è£…ä¾èµ–åº“ï¼štorch, torchvision, pillow")